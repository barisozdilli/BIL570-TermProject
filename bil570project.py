# -*- coding: utf-8 -*-
"""bil570project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sNZ1sfmbJYKt9fklZAsCUPLe413ANqAB
"""

from google.colab import drive
import sklearn
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
from keras.models import Sequential
from keras.layers import Dense
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from scipy.spatial import distance
from sklearn import decomposition
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
drive.mount('/content/drive')#Kodun drive dan izin aldığı kod

path = '/content/drive/My Drive/Bil470 570/'

X_csv = pd.read_csv(path+"dengue_features_train.csv")
y_csv = pd.read_csv(path+"dengue_labels_train.csv")
x_test_csv = pd.read_csv(path+"dengue_features_test.csv")
y_test_csv = pd.read_csv(path+"submission_format.csv")
X_csv = X_csv.replace(to_replace=['sj', 'iq'], value=[0, 1])
x_test_csv = x_test_csv.replace(to_replace=['sj', 'iq'], value=[0, 1])
print("X_csv",X_csv)
X_csv.fillna(method='ffill', inplace=True)
x_test_csv.fillna(method='ffill', inplace=True)
print("X_csv",x_test_csv)

def extract_past(X,frame_size):
   features = np.ones((X.shape[0],X.shape[1]*frame_size))
   for i in range(X.shape[0]-frame_size):
       features[i+frame_size] = np.reshape(X[i:i+frame_size],(X.shape[1]*frame_size))
   return features

def moving_average(a, n=3) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n

features = ['reanalysis_specific_humidity_g_per_kg', 
                 'reanalysis_dew_point_temp_k', 
                 'station_avg_temp_c', 
                 'station_min_temp_c','weekofyear']
"""
'reanalysis_specific_humidity_g_per_kg', 
                 'reanalysis_dew_point_temp_k', 
                 'station_avg_temp_c', 
                 'station_min_temp_c'
"""
#
#features.extend(X_csv.columns[4:])

#X_csv['weekofyear'] = (X_csv['weekofyear'] - 30).abs()

y = y_csv["total_cases"].values
shifting_amount = 1
window_size = 0

#y_csv = y_csv[y_csv['year'] == 2007]
#X_csv= X_csv[X_csv['year'] == 2007]

y_original_sj = y_csv[X_csv['city'] == 0]['total_cases'].values
y_original_iq = y_csv[X_csv['city'] == 1]['total_cases'].values
X_sj = X_csv[X_csv['city'] == 0][features].values#replace(0,1).pct_change(shifting_amount)[shifting_amount:].values
y_sj = y_csv[X_csv['city'] == 0]['total_cases'].values#replace(0,1).pct_change(shifting_amount)[shifting_amount:].values
X_iq = X_csv[X_csv['city'] == 1][features].values#replace(0,1).pct_change(shifting_amount)[shifting_amount:].values
y_iq = y_csv[X_csv['city'] == 1]['total_cases'].values#replace(0,1).pct_change(shifting_amount)[shifting_amount:].values
print("Xcsv",X_csv['weekofyear'])
#past_X_sj = extract_past(X_sj,window_size)
#past_X_iq = extract_past(X_iq,window_size)

#X_sj = np.concatenate((X_sj,past_X_sj),axis=1)
#X_iq = np.concatenate((X_iq,past_X_iq),axis=1)

#n = 0
#y_iq = moving_average(y_iq,n)
#y_sj = moving_average(y_sj,n)
#X_iq = X_iq[n-1:]
#X_sj = X_sj[n-1:]

memory_X_sj = np.ones((y_sj.shape[0],shifting_amount))
for i in range(memory_X_sj.shape[1]):
    memory_X_sj[i+1:,i] = y_sj[0:-(i+1)] 

X_sj = np.concatenate((X_sj,memory_X_sj),axis=1)

memory_X_iq = np.ones((y_iq.shape[0],shifting_amount))
for i in range(memory_X_iq.shape[1]):
    memory_X_iq[i+1:,i] = y_iq[0:-(i+1)] 

X_iq = np.concatenate((X_iq,memory_X_iq),axis=1)
#x_test_csv['weekofyear'] = (x_test_csv['weekofyear'] - 30).abs()
x_test = x_test_csv[features].values
x_test_sj = x_test_csv[x_test_csv['city'] == 0][features].values
x_test_iq = x_test_csv[x_test_csv['city'] == 1][features].values

#past_X_sj_test = extract_past(x_test_sj,window_size)
#past_X_iq_test = extract_past(x_test_iq,window_size)

#x_test_sj = np.concatenate((x_test_sj,past_X_sj_test),axis=1)
#x_test_iq = np.concatenate((x_test_iq,past_X_iq_test),axis=1)

X_train_iq,X_validation_iq,y_train_iq,y_validation_iq = train_test_split(X_iq,y_iq,test_size = 0.9,shuffle=False)
#MLPRegressor(random_state=1,hidden_layer_sizes=(30),max_iter=2000,validation_fraction=0.4)
regr_iq =LinearRegression(normalize= True)#MLPRegressor(random_state=1,hidden_layer_sizes=(30),max_iter=2000)#LinearRegression(normalize= True)#MLPRegressor(random_state=1,hidden_layer_sizes=(50,10),max_iter=2000)# LinearRegression()#RandomForestRegressor(max_depth=10, random_state=0)#LinearRegression()# RandomForestRegressor(max_depth=3, random_state=0)#MLPRegressor(random_state=1,hidden_layer_sizes=(100,100,100),max_iter=2000)# LinearRegression()#MLPRegressor(random_state=1,hidden_layer_sizes=(10),max_iter=2000)
regr_iq.fit(X_iq,y_iq)
#print("regr_sj weights",regr_iq.coef_)
#print("intecept",regr_iq.intercept_)
y_train_predict_iq = regr_iq.predict(X_train_iq)
y_predict_validation_iq = regr_iq.predict(X_validation_iq)
print("Training error",mean_absolute_error(y_train_predict_iq, y_train_iq))
print("Validation error",mean_absolute_error(y_validation_iq, y_predict_validation_iq))

X_train_sj,X_validation_sj,y_train_sj,y_validation_sj = train_test_split(X_sj,y_sj,test_size = 0.5,shuffle=False)
print("X_train_sj",X_sj.shape)
#MLPRegressor(random_state=1,hidden_layer_sizes=(30),max_iter=2000,validation_fraction=0.4)
regr_sj =LinearRegression(normalize= True)
regr_sj.fit(X_sj,y_sj)
#print("regr_sj weights",regr_sj.coef_)
#print("intecept",regr_sj.intercept_)
y_train_predict_sj = regr_sj.predict(X_train_sj)
y_predict_validation_sj = regr_sj.predict(X_validation_sj)
print("Training error",mean_absolute_error(y_train_predict_sj, y_train_sj))
print("Validation error",mean_absolute_error(y_validation_sj, y_predict_validation_sj))

#generated_signal = detransform(y_original_sj[0],y_train_predict_sj)
plt.plot(y_predict_validation_iq,'-g')
plt.plot(y_validation_iq,'-b')

plt.plot(y_predict_validation_sj,'-g')
plt.plot(y_validation_sj,'-b')

def predict_test(x_test,y_in,regr):
     outputs = np.ones(x_test.shape[0])
     y = np.copy(y_in)
     for i in range(len(x_test)):
         features = x_test[i]
         x = np.append(features,y)
         temp = y[0]
         y[0] = regr.predict(np.reshape(x,(1,-1)))
         outputs[i] = y[0]
         for i in range(1,y.shape[0]):
            temp2 = y[i]
            y[i] = temp
            temp = temp2
     return outputs



outputs_sj = predict_test(x_test_sj,y_sj[-shifting_amount:],regr_sj)
outputs_iq = predict_test(x_test_iq,y_iq[-shifting_amount:],regr_iq)

#y_test_prediction_sj = regr_sj.predict(x_test_sj)
#y_test_prediction_iq = regr_iq.predict(x_test_iq)

#y_test_prediction = model.predict(x_test)
y_test_prediction = np.concatenate((outputs_sj,outputs_iq),axis = None)
y_test_prediction = y_test_prediction.astype('int64') 
#print("y_test",y_test_prediction.shape)
#print("y_test_predict",y_test_prediction)

plt.plot(outputs_sj,'-b')

y_test_csv.iloc[:,-1] = y_test_prediction

#y_test_csv.iloc[:,-1][y_test_csv["city"] == 'sj' ] = 34
#y_test_csv.iloc[:,-1][y_test_csv["city"] == 'iq' ] =8
y_test_csv.to_csv(path+"output.csv",index=False)
y_test_csv.to_csv(path+"output.csv",index=False)
print("y_test_csv",y_test_csv)

random_forest_depth = pd.read_csv(path+"/models/random_forest_depth=3_full_training_Set_5_ds_rs.csv")
moving_average_linear_regression = pd.read_csv(path+"/models/moving_average=2_linear_regression.csv")
time_series_prediction_w_linear_reg = pd.read_csv(path+"/models/time_series_prediction_w=1_full_linear_regression.csv")
moving_average_linear_regression_weekly = pd.read_csv(path+"/models/moving_average=2_linear_regression.csv")

random_forest_depth_sj = random_forest_depth[random_forest_depth['city']=='sj']
random_forest_depth_iq = random_forest_depth[random_forest_depth['city']=='iq']

moving_average_linear_regression_sj = moving_average_linear_regression[moving_average_linear_regression['city']=='sj']
moving_average_linear_regression_iq = moving_average_linear_regression[moving_average_linear_regression['city']=='iq']

time_series_prediction_w_linear_reg_sj = time_series_prediction_w_linear_reg[time_series_prediction_w_linear_reg['city']=='sj']
time_series_prediction_w_linear_reg_iq = time_series_prediction_w_linear_reg[time_series_prediction_w_linear_reg['city']=='iq']

moving_average_linear_regression_weekly_sj = moving_average_linear_regression_weekly[moving_average_linear_regression_weekly['city']=='sj']
moving_average_linear_regression_weekly_iq = moving_average_linear_regression_weekly[moving_average_linear_regression_weekly['city']=='iq']

plt.plot(random_forest_depth_sj['total_cases'].values, label='Random_forest')
plt.plot(moving_average_linear_regression_sj['total_cases'].values,label='linear regression moving average')
plt.plot(time_series_prediction_w_linear_reg_sj['total_cases'].values,label='linear regression')
plt.title("City Sj Prediction Plots")
plt.legend()
plt.xlabel('days', fontsize=12)
plt.ylabel('total cases', fontsize=12)
plt.savefig('fig1.png', dpi = 300)
#plt.show()

plt.plot(random_forest_depth_iq['total_cases'].values, label='Random_forest')
plt.plot(moving_average_linear_regression_iq['total_cases'].values,label='linear regression moving average')
plt.plot(time_series_prediction_w_linear_reg_iq['total_cases'].values,label='linear regression')
leg = plt.legend()
plt.title("City Iq Prediction Plots")
plt.legend()
plt.xlabel('days', fontsize=12)
plt.ylabel('total cases', fontsize=12)
plt.savefig('fig2.png', dpi = 300)

plt.hist(moving_average_linear_regression_sj['total_cases'].values,density=True)
plt.show()

plt.hist(np.diff(y_test_prediction),density =True)
plt.show()